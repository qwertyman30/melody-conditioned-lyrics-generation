{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "from numba import cuda\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "from torchmetrics.text.bert import BERTScore\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662135f",
   "metadata": {},
   "source": [
    "## Preprocessing, load tokenizers, set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3429054",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed = 42\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5476b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = np.load(\"data/sequences.npy\")\n",
    "print(data_matrix.shape)\n",
    "\n",
    "lyrics = data_matrix[:, :, 0]\n",
    "notes = data_matrix[:, :, 1]\n",
    "durations = data_matrix[:, :, 2]\n",
    "rests = data_matrix[:, :, 3]\n",
    "\n",
    "print(lyrics.shape, notes.shape, durations.shape, rests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        tokenizer = data['tokenizer']\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd719eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_lyr = load_tokenizer(\"tokenizers/tokenizer_lyr.pkl\")\n",
    "tokenizer_note = load_tokenizer(\"tokenizers/tokenizer_note.pkl\")\n",
    "tokenizer_duration = load_tokenizer(\"tokenizers/tokenizer_duration.pkl\")\n",
    "tokenizer_rest = load_tokenizer(\"tokenizers/tokenizer_rest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44df1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_songs = len(lyrics)\n",
    "num_samples = 6848\n",
    "train_inds = np.random.choice(np.arange(num_songs), size=num_samples, replace=False)\n",
    "test_inds = np.delete(np.arange(num_songs), train_inds)\n",
    "\n",
    "train_lyrics = [lyrics[i] for i in train_inds]\n",
    "test_lyrics = [lyrics[i] for i in test_inds]\n",
    "\n",
    "train_notes = [notes[i] for i in train_inds]\n",
    "test_notes = [notes[i] for i in test_inds]\n",
    "\n",
    "train_durations = [durations[i] for i in train_inds]\n",
    "test_durations = [durations[i] for i in test_inds]\n",
    "\n",
    "train_rests = [rests[i] for i in train_inds]\n",
    "test_rests = [rests[i] for i in test_inds]\n",
    "\n",
    "# General params\n",
    "vocab_size = min(len(tokenizer_lyr.word_index) + 1, 10000)\n",
    "notes_size = len(tokenizer_note.word_index) + 1\n",
    "durations_size = len(tokenizer_duration.word_index) + 1\n",
    "rests_size = len(tokenizer_rest.word_index) + 1\n",
    "\n",
    "pad_id_lyr = tokenizer_lyr.word_index[\"eos\"]\n",
    "start_id_lyr = tokenizer_lyr.word_index[\"bos\"]\n",
    "\n",
    "pad_id_note = tokenizer_note.word_index[\"eos\"]\n",
    "start_id_note = tokenizer_note.word_index[\"bos\"]\n",
    "\n",
    "pad_id_duration = tokenizer_duration.word_index[\"eos\"]\n",
    "start_id_duration = tokenizer_duration.word_index[\"bos\"]\n",
    "\n",
    "pad_id_rest = tokenizer_rest.word_index[\"eos\"]\n",
    "start_id_rest = tokenizer_rest.word_index[\"bos\"]\n",
    "\n",
    "max_seq_len = lyrics.shape[1]\n",
    "batch_size = 32\n",
    "\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "# Generator params\n",
    "g_dropout = 0.3\n",
    "g_embed_dim = 32\n",
    "g_hidden = 32\n",
    "pretrain_epochs_gen = 120\n",
    "g_lr_pretrain = 0.01\n",
    "g_lr_adv = 1e-4\n",
    "\n",
    "# Discriminator params\n",
    "d_embed_dim = 64\n",
    "d_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "d_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n",
    "d_dropout_prob = 0.2\n",
    "d_lr = 1e-4\n",
    "\n",
    "\n",
    "rollout_num = 16\n",
    "clip_norm = 5.0\n",
    "\n",
    "adversarial_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d83f9",
   "metadata": {},
   "source": [
    "## Model initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal_(tensor, mean=0, std=1):\n",
    "    \"\"\"\n",
    "    Implemented by @ruotianluo\n",
    "    See https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/15\n",
    "    \"\"\"\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, note_size,\n",
    "                 duration_size, rest_size, max_seq_len, pad_id_lyr,\n",
    "                 pad_id_note, pad_id_dur, pad_id_rest, gpu=False):\n",
    "        super(LSTMGenerator, self).__init__()\n",
    "        self.name = 'vanilla'\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.note_size = vocab_size\n",
    "        self.duration_size = vocab_size\n",
    "        self.rest_size = vocab_size\n",
    "        self.pad_id_lyr = pad_id_lyr\n",
    "        self.pad_id_note = pad_id_note\n",
    "        self.pad_id_dur = pad_id_dur\n",
    "        self.pad_id_rest = pad_id_rest\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.embeddings_lyr = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_id_lyr)\n",
    "        self.embeddings_note = nn.Embedding(note_size, embedding_dim, padding_idx=pad_id_note)\n",
    "        self.embeddings_dur = nn.Embedding(duration_size, embedding_dim, padding_idx=pad_id_dur)\n",
    "        self.embeddings_rest = nn.Embedding(rest_size, embedding_dim, padding_idx=pad_id_rest)\n",
    "        self.lstm = nn.LSTM(embedding_dim*4, hidden_dim, batch_first=True)\n",
    "        self.lstm2out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp, mel, hidden, need_hidden=False):\n",
    "        \"\"\"\n",
    "        Embeds input and applies LSTM\n",
    "        :param inp: batch_size * seq_len\n",
    "        :param hidden: (h, c)\n",
    "        :param need_hidden: if return hidden, use for sampling\n",
    "        \"\"\"\n",
    "        if len(mel.shape) == 2:\n",
    "            notes = mel[:, 0]\n",
    "            durations = mel[:, 1]\n",
    "            rests = mel[:, 2]\n",
    "        else:\n",
    "            notes = mel[:, :, 0]\n",
    "            durations = mel[:, :, 1]\n",
    "            rests = mel[:, :, 2]\n",
    "\n",
    "        emb_lyr = self.embeddings_lyr(inp)  # batch_size * len * embedding_dim\n",
    "        emb_note = self.embeddings_note(notes)\n",
    "        emb_dur = self.embeddings_dur(durations)\n",
    "        emb_rest = self.embeddings_rest(rests)\n",
    "        \n",
    "        if len(inp.size()) == 1:\n",
    "            emb_lyr = emb_lyr.unsqueeze(1)  # batch_size * 1 * embedding_dim\n",
    "            emb_note = emb_note.unsqueeze(1)\n",
    "            emb_dur = emb_dur.unsqueeze(1)\n",
    "            emb_rest = emb_rest.unsqueeze(1)\n",
    "            \n",
    "        emb = torch.cat([emb_lyr, emb_note, emb_dur, emb_rest], dim=2)\n",
    "\n",
    "        out, hidden = self.lstm(emb, hidden)  # out: batch_size * seq_len * hidden_dim\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)  # out: (batch_size * len) * hidden_dim\n",
    "        out = self.lstm2out(out)  # (batch_size * seq_len) * vocab_size\n",
    "        pred = self.softmax(out)\n",
    "\n",
    "        if need_hidden:\n",
    "            return pred, hidden\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    def sample(self, melody, num_samples, batch_size, start_letter=1):\n",
    "        \"\"\"\n",
    "        Samples the network and returns num_samples samples of length max_seq_len.\n",
    "        :return samples: num_samples * max_seq_length (a sampled sequence in each row)\n",
    "        \"\"\"\n",
    "        num_batch = num_samples // batch_size if num_samples != batch_size else 1\n",
    "        samples = torch.zeros(num_batch * batch_size, self.max_seq_len).long()\n",
    "\n",
    "        # Generate sentences with multinomial sampling strategy\n",
    "        for b in range(num_batch):\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "            inp = torch.LongTensor([start_letter] * batch_size)\n",
    "            mel_batch = melody[b * batch_size:(b+1) * batch_size, :]\n",
    "            if self.gpu:\n",
    "                inp = inp.cuda()\n",
    "                mel_batch = mel_batch.cuda()\n",
    "\n",
    "            for i in range(self.max_seq_len):\n",
    "                y = mel_batch[:, i, :]\n",
    "                out, hidden = self.forward(inp, y, hidden, need_hidden=True)  # out: batch_size * vocab_size\n",
    "                next_token = torch.multinomial(torch.exp(out), 1)  # batch_size * 1 (sampling from each row)\n",
    "                samples[b * batch_size:(b + 1) * batch_size, i] = next_token.view(-1)\n",
    "                inp = next_token.view(-1)\n",
    "        samples = samples[:num_samples]\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                truncated_normal_(param, std=stddev)\n",
    "\n",
    "    def init_hidden(self, batch_size=32):\n",
    "        h = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "        c = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "\n",
    "        if self.gpu:\n",
    "            return h.cuda(), c.cuda()\n",
    "        else:\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc38ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqGAN_G(LSTMGenerator):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, note_size,\n",
    "                 duration_size, rest_size, max_seq_len, pad_id_lyr,\n",
    "                 pad_id_note, pad_id_dur, pad_id_rest, gpu=False):\n",
    "        super(SeqGAN_G, self).__init__(embedding_dim, hidden_dim, vocab_size, note_size,\n",
    "                                       duration_size, rest_size, max_seq_len, pad_id_lyr,\n",
    "                                       pad_id_note, pad_id_dur, pad_id_rest, gpu)\n",
    "        self.name = 'seqgan'\n",
    "\n",
    "    def batchPGLoss(self, inp, mel, target, reward):\n",
    "        \"\"\"\n",
    "        Returns a policy gradient loss\n",
    "        :param inp: batch_size x seq_len, inp should be target with <s> (start letter) prepended\n",
    "        :param target: batch_size x seq_len\n",
    "        :param reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding sentence)\n",
    "        :return loss: policy loss\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inp.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        out = self.forward(inp, mel, hidden).view(batch_size, self.max_seq_len, self.vocab_size)\n",
    "        target_onehot = F.one_hot(target, self.vocab_size).float()  # batch_size * seq_len * vocab_size\n",
    "        pred = torch.sum(out * target_onehot, dim=-1)  # batch_size * seq_len\n",
    "        loss = -torch.sum(pred * reward)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2136bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDiscriminator(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, filter_sizes, num_filters, padding_idx, gpu=False,\n",
    "                 dropout=0.2):\n",
    "        super(CNNDiscriminator, self).__init__()\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.feature_dim = sum(num_filters)\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, n, (f, embed_dim)) for (n, f) in zip(num_filters, filter_sizes)\n",
    "        ])\n",
    "        self.highway = nn.Linear(self.feature_dim, self.feature_dim)\n",
    "        self.feature2out = nn.Linear(self.feature_dim, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Get final predictions of discriminator\n",
    "        :param inp: batch_size * seq_len\n",
    "        :return: pred: batch_size * 2\n",
    "        \"\"\"\n",
    "        feature = self.get_feature(inp)\n",
    "        pred = self.feature2out(self.dropout(feature))\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def get_feature(self, inp):\n",
    "        \"\"\"\n",
    "        Get feature vector of given sentences\n",
    "        :param inp: batch_size * max_seq_len\n",
    "        :return: batch_size * feature_dim\n",
    "        \"\"\"\n",
    "        emb = self.embeddings(inp).unsqueeze(1)  # batch_size * 1 * max_seq_len * embed_dim\n",
    "        convs = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  # [batch_size * num_filter * length]\n",
    "        pools = [F.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in convs]  # [batch_size * num_filter]\n",
    "        pred = torch.cat(pools, 1)  # tensor: batch_size * feature_dim\n",
    "        highway = self.highway(pred)\n",
    "        pred = torch.sigmoid(highway) * F.relu(highway) + (1. - torch.sigmoid(highway)) * pred  # highway\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                truncated_normal_(param, std=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10040e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqGAN_D(CNNDiscriminator):\n",
    "    def __init__(self, embed_dim, vocab_size, padding_idx, dis_filter_sizes,\n",
    "                 dis_num_filters, gpu=False, dropout=0.25):\n",
    "        super(SeqGAN_D, self).__init__(embed_dim, vocab_size, dis_filter_sizes,\n",
    "                                       dis_num_filters, padding_idx, gpu, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3318d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenDataIter:\n",
    "    def __init__(self, samples, melodies, batch_size, max_seq_len, start_letter=1, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.start_letter = start_letter\n",
    "\n",
    "        self.loader = DataLoader(\n",
    "            dataset=GANDataset(self.__read_data__(samples, melodies)),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            drop_last=True)\n",
    "\n",
    "        self.input = self._all_data_('lyric')\n",
    "        self.melody = self._all_data_('melody')\n",
    "        self.target = self._all_data_('target')\n",
    "\n",
    "    def __read_data__(self, samples, melodies):\n",
    "        \"\"\"\n",
    "        input: same as target, but start with start_letter.\n",
    "        \"\"\"\n",
    "        # global all_data\n",
    "        inp, target = self.prepare(samples, melodies, self.start_letter)\n",
    "        lyr, mel = inp\n",
    "        all_data = [{'lyric': l, 'melody': m, 'target': t} for (l, m, t) in zip(lyr, mel, target)]\n",
    "        return all_data\n",
    "\n",
    "    def random_batch(self):\n",
    "        \"\"\"Randomly choose a batch from loader, please note that the data should not be shuffled.\"\"\"\n",
    "        idx = random.randint(0, len(self.loader) - 1)\n",
    "        return list(self.loader)[idx]\n",
    "\n",
    "    def _all_data_(self, col):\n",
    "        return torch.cat([data[col].unsqueeze(0) for data in self.loader.dataset.data], 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare(samples, melodies, start_id, gpu=False):\n",
    "        \"\"\"Add start_letter to samples as inp, target same as samples\"\"\"\n",
    "        inp = torch.zeros(samples.size()).long()\n",
    "        target = samples\n",
    "        inp[:, 0] = start_id\n",
    "        inp[:, 1:] = target[:, :max_seq_len - 1]\n",
    "\n",
    "        if gpu:\n",
    "            return (inp.cuda(), melodies.cuda()), target.cuda()\n",
    "        return (inp, melodies), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(opt, loss, model=None, retain_graph=False):\n",
    "    opt.zero_grad()\n",
    "    loss.backward(retain_graph=retain_graph)\n",
    "    if model is not None:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_epoch(model, data_loader, criterion, optimizer, cuda=True):\n",
    "    total_loss = 0\n",
    "    for data in data_loader:\n",
    "        lyr, mel, target = data['lyric'], data['melody'], data['target']\n",
    "        if cuda:\n",
    "            lyr, mel, target = lyr.cuda(), mel.cuda(), target.cuda()\n",
    "\n",
    "        hidden = model.init_hidden(data_loader.batch_size)\n",
    "        pred = model.forward(lyr, mel, hidden)\n",
    "        loss = criterion(pred, target.view(-1))\n",
    "        optimize(optimizer, loss, model)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174df685",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea679627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_generator(gen, gen_opt, data_loader, criterion, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pre-training for the generator\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    progress = tqdm(range(epochs))\n",
    "    for epoch in progress:\n",
    "        pre_loss = train_gen_epoch(gen, data_loader, criterion, gen_opt)\n",
    "        losses.append(pre_loss)\n",
    "        progress.set_description(\"EPOCH: {}, LOSS: {}\".format(epoch, pre_loss))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_lyrics_train = torch.LongTensor(train_lyrics)\n",
    "sequences_notes_train = torch.LongTensor(train_notes)\n",
    "sequences_durations_train = torch.LongTensor(train_durations)\n",
    "sequences_rests_train = torch.LongTensor(train_rests)\n",
    "\n",
    "sequences_notes_train = sequences_notes_train.unsqueeze(2)\n",
    "sequences_durations_train = sequences_durations_train.unsqueeze(2)\n",
    "sequences_rests_train = sequences_rests_train.unsqueeze(2)\n",
    "\n",
    "train_melodies = torch.cat([sequences_notes_train, sequences_durations_train, sequences_rests_train], dim=2)\n",
    "\n",
    "gen_data_iter = GenDataIter(sequences_lyrics_train, train_melodies, batch_size, max_seq_len, start_letter=start_id_lyr)\n",
    "\n",
    "train_melodies.shape, sequences_lyrics_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = SeqGAN_G(g_embed_dim, g_hidden, vocab_size, notes_size, durations_size, rests_size,\n",
    "               max_seq_len, pad_id_lyr, pad_id_note, pad_id_duration, pad_id_rest, True).cuda()\n",
    "\n",
    "gen_opt = optim.Adam(gen.parameters(), lr=g_lr_pretrain)\n",
    "gen_adv_opt = optim.Adam(gen.parameters(), lr=g_lr_adv)\n",
    "mle_criterion = nn.NLLLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_pretrain = pretrain_generator(gen, gen_opt, gen_data_iter.loader, mle_criterion, pretrain_epochs_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f26f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_pretrain)\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.title(\"Pretraining Losses Generator\")\n",
    "plt.savefig(\"Pretraining Losses SeqGenerator.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f79a6",
   "metadata": {},
   "source": [
    "## Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROLLOUT:\n",
    "    def __init__(self, gen, gpu=True):\n",
    "        self.gen = gen\n",
    "        self.old_model = copy.deepcopy(gen)\n",
    "        self.max_seq_len = gen.max_seq_len\n",
    "        self.vocab_size = gen.vocab_size\n",
    "        self.gpu = gpu\n",
    "\n",
    "    def rollout_mc_search(self, sentences, melodies, given_num):\n",
    "        \"\"\"\n",
    "        fill up remain tokens with MC search\n",
    "        :param sentences: size of batch_size * max_seq_len\n",
    "        :param given_num:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = sentences.size(0)\n",
    "\n",
    "        # get current state\n",
    "        hidden = self.gen.init_hidden(batch_size)\n",
    "        # for i in range(given_num):\n",
    "        inp = sentences[:, :given_num]\n",
    "        mel = melodies[:, :given_num, :]\n",
    "        out, hidden = self.gen.forward(inp, mel, hidden, need_hidden=True)\n",
    "        out = out.view(batch_size, -1, self.vocab_size)[:, -1]\n",
    "\n",
    "        samples = torch.zeros(batch_size, self.max_seq_len).long()\n",
    "        samples[:, :given_num] = sentences[:, :given_num]\n",
    "\n",
    "        if self.gpu:\n",
    "            samples = samples.cuda()\n",
    "\n",
    "        # MC search\n",
    "        for i in range(given_num, self.max_seq_len):\n",
    "            out = torch.multinomial(torch.exp(out), 1)\n",
    "            samples[:, i] = out.view(-1).data\n",
    "            inp = out.view(-1)\n",
    "            mel = melodies[:, i, :]\n",
    "            mel = torch.squeeze(mel, dim=1)\n",
    "\n",
    "            out, hidden = self.gen.forward(inp, mel, hidden, need_hidden=True)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def get_reward(self, sentences, melodies, rollout_num, dis, current_k=0):\n",
    "        \"\"\"\n",
    "        get reward via Monte Carlo search\n",
    "        :param sentences: size of batch_size * max_seq_len\n",
    "        :param rollout_num:\n",
    "        :param dis:\n",
    "        :param current_k: current training gen\n",
    "        :return: reward: [batch_size]\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            batch_size = sentences.size(0)\n",
    "            rewards = torch.zeros([rollout_num * self.max_seq_len, batch_size]).float()\n",
    "            if self.gpu:\n",
    "                rewards = rewards.cuda()\n",
    "            idx = 0\n",
    "            for i in range(rollout_num):\n",
    "                for given_num in range(1, self.max_seq_len + 1):\n",
    "                    samples = self.rollout_mc_search(sentences, melodies, given_num)\n",
    "                    out = dis.forward(samples)\n",
    "                    out = F.softmax(out, dim=-1)\n",
    "                    reward = out[:, current_k + 1]\n",
    "                    rewards[idx] = reward\n",
    "                    idx += 1\n",
    "\n",
    "        # rewards = torch.mean(rewards, dim=0)\n",
    "        rewards = torch.mean(rewards.view(batch_size, self.max_seq_len, rollout_num), dim=-1)\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_and_end(lyrics):\n",
    "    clean_lyrics = []\n",
    "    for lyric in lyrics:\n",
    "        removal_list = [\"BOS\",\"EOS\", \"eos\", \"bos\"]\n",
    "        lyric_list = lyric.split()\n",
    "        final_list = [word for word in lyric_list if word not in removal_list]\n",
    "        final_string = ' '.join(final_list)\n",
    "        clean_lyrics.append(final_string)\n",
    "\n",
    "    return clean_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisDataIter:\n",
    "    def __init__(self, pos_samples, neg_samples):\n",
    "        self.batch_size = 32\n",
    "        self.max_seq_len = 20\n",
    "        self.start_letter = 0\n",
    "\n",
    "        self.loader = DataLoader(\n",
    "            dataset=GANDataset(self.__read_data__(pos_samples, neg_samples)),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True)\n",
    "\n",
    "    def __read_data__(self, pos_samples, neg_samples):\n",
    "        \"\"\"\n",
    "        input: same as target, but start with start_letter.\n",
    "        \"\"\"\n",
    "        inp, target = self.prepare(pos_samples, neg_samples)\n",
    "        all_data = [{'input': i, 'target': t} for (i, t) in zip(inp, target)]\n",
    "        return all_data\n",
    "\n",
    "    def random_batch(self):\n",
    "        idx = random.randint(0, len(self.loader) - 1)\n",
    "        return list(self.loader)[idx]\n",
    "\n",
    "    def prepare(self, pos_samples, neg_samples):\n",
    "        \"\"\"Build inp and target\"\"\"\n",
    "        inp = torch.cat((pos_samples, neg_samples), dim=0).long().detach()  # !!!need .detach()\n",
    "        target = torch.ones(inp.size(0)).long()\n",
    "        target[pos_samples.size(0):] = 0\n",
    "\n",
    "        # shuffle\n",
    "        perm = torch.randperm(inp.size(0))\n",
    "        inp = inp[perm].cuda()\n",
    "        target = target[perm].cuda()\n",
    "\n",
    "        return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = SeqGAN_D(d_embed_dim, vocab_size, pad_id_lyr, d_filter_sizes, d_num_filters, gpu=True).cuda()\n",
    "dis_opt = optim.Adam(dis.parameters(), lr=d_lr)\n",
    "dis_criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47562ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train_generator(gen, dis, melody, batch_size, rollout_num, gen_adv_opt, start_letter, g_step, cuda=True):\n",
    "    \"\"\"\n",
    "    The gen is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "    rollout_func = ROLLOUT(gen, True)\n",
    "    total_g_loss = 0\n",
    "    for step in range(g_step):\n",
    "        (inp, mel), target = GenDataIter.prepare(gen.sample(melody, batch_size, batch_size, start_letter),\n",
    "                                                 melody, start_letter, gpu=True)\n",
    "        if cuda:\n",
    "            inp = inp.cuda()\n",
    "            mel = mel.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # ===Train===\n",
    "        rewards = rollout_func.get_reward(target, mel, rollout_num, dis)\n",
    "        adv_loss = gen.batchPGLoss(inp, mel, target, rewards)\n",
    "        optimize(gen_adv_opt, adv_loss)\n",
    "        total_g_loss += adv_loss.item()\n",
    "    return total_g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dis_epoch(model, data_loader, criterion, optimizer, CUDA=True):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    for i, data in enumerate(data_loader):\n",
    "        inp, target = data['input'], data['target']\n",
    "        if CUDA:\n",
    "            inp, target = inp.cuda(), target.cuda()\n",
    "\n",
    "        pred = model.forward(inp)\n",
    "        loss = criterion(pred, target)\n",
    "        optimize(optimizer, loss, model)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += torch.sum((pred.argmax(dim=-1) == target)).item()\n",
    "        total_num += inp.size(0)\n",
    "\n",
    "    total_loss /= len(data_loader)\n",
    "    total_acc /= total_num\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(gen, dis, batch_size, train_data,\n",
    "                        dis_criterion, dis_opt, d_step, d_epoch):\n",
    "    \"\"\"\n",
    "    Training the discriminator on real_data_samples (positive) and generated samples from gen (negative).\n",
    "    Samples are drawn d_step times, and the discriminator is trained for d_epoch d_epoch.\n",
    "    \"\"\"\n",
    "    # prepare loader for validate\n",
    "    global d_loss, train_acc\n",
    "    losses, accs = [], []\n",
    "    for step in range(d_step):\n",
    "        # prepare loader for training\n",
    "        targets = train_data.target\n",
    "        inds = np.arange(targets.shape[0])\n",
    "        rand_inds = np.random.choice(inds, 8 * batch_size)\n",
    "        pos_samples = gen_data_iter.target[rand_inds]\n",
    "        neg_samples = gen.sample(gen_data_iter.melody, 8 * batch_size, batch_size)\n",
    "        dis_data = DisDataIter(pos_samples, neg_samples)\n",
    "        d_losses, train_accs = [], []\n",
    "        for epoch in range(d_epoch):\n",
    "            # ===Train===\n",
    "            d_loss, train_acc = train_dis_epoch(dis, dis_data.loader, dis_criterion, dis_opt)\n",
    "            d_losses.append(d_loss)\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "        losses.append(np.mean(d_losses))\n",
    "        accs.append(np.mean(train_accs))\n",
    "    return losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768938e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_train(gen, dis, gen_adv_opt, dis_adv_opt, train_data, batch_size,\n",
    "                      dis_criterion, rollout_num, epochs, start_letter=1):\n",
    "    progress = tqdm(range(epochs))\n",
    "    g_losses, d_losses, d_accs = [], [], []\n",
    "    for adv_epoch in progress:\n",
    "        rand_batch = train_data.random_batch()\n",
    "        lyric = rand_batch[\"lyric\"]\n",
    "        melody = rand_batch[\"melody\"]\n",
    "        target = rand_batch[\"target\"]\n",
    "        g_loss = adv_train_generator(gen, dis, melody, batch_size, rollout_num, gen_adv_opt, start_letter, 2)\n",
    "        d_loss, accs = train_discriminator(gen, dis, batch_size, gen_data_iter, dis_criterion, dis_adv_opt, 1, 1)\n",
    "        g_losses.append(g_loss)\n",
    "        d_losses.append(np.mean(d_loss))\n",
    "        d_accs.append(np.mean(accs))\n",
    "        progress.set_description('g_loss: %.4f, d_loss: %.4f, g_acc: %.4f' % (g_loss, np.mean(d_loss), np.mean(accs)))\n",
    "\n",
    "    return g_losses, d_losses, d_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b16963",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_losses, d_losses, d_accs = adversarial_train(gen, dis, gen_adv_opt, dis_opt,\n",
    "                                               gen_data_iter, batch_size, dis_criterion,\n",
    "                                               rollout_num, adversarial_epochs, start_id_lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses)\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.title(\"Advesarial Losses Generator\")\n",
    "plt.savefig(\"Advesarial Losses SeqGenerator.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73afba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses)\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.title(\"Advesarial Losses SeqDiscriminator\")\n",
    "plt.savefig(\"Advesarial Losses SeqDiscriminator.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_accs)\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.title(\"Advesarial Accuracies SeqDiscriminator\")\n",
    "plt.savefig(\"Advesarial Accuracies SeqDiscriminator.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90379f31",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_is = np.random.choice(test_inds, 80)\n",
    "\n",
    "test_nos = np.expand_dims(np.array([notes[i] for i in test_is]), axis=2)\n",
    "test_dus = np.expand_dims(np.array([durations[i] for i in test_is]), axis=2)\n",
    "test_res = np.expand_dims(np.array([rests[i] for i in test_is]), axis=2)\n",
    "test_lyr = [lyrics[i] for i in test_is]\n",
    "\n",
    "test_mels = np.concatenate([test_nos, test_dus, test_res], axis=2)\n",
    "test_mels = torch.LongTensor(test_mels)\n",
    "test_mels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = gen.sample(test_mels, 80, 16, start_id_lyr)\n",
    "preds = tokenizer_lyr.sequences_to_texts(samples.numpy())\n",
    "orig = tokenizer_lyr.sequences_to_texts(test_lyr)\n",
    "\n",
    "preds = remove_start_and_end(preds)\n",
    "orig = remove_start_and_end(orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ecd4a",
   "metadata": {},
   "source": [
    "## BLEU Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleus_4, bleus_3, bleus_2 = [], [], []\n",
    "for test_ref, test_pred in tqdm(zip(orig, preds)):\n",
    "    bleu4 = sentence_bleu(test_ref, test_pred, smoothing_function=chencherry.method7)\n",
    "    bleu3 = sentence_bleu(test_ref, test_pred, weights=[1/3, 1/3, 1/3], smoothing_function=chencherry.method7)\n",
    "    bleu2 = sentence_bleu(test_ref, test_pred, weights=[1/2, 1/2], smoothing_function=chencherry.method7)\n",
    "    bleus_4.append(bleu4)\n",
    "    bleus_3.append(bleu3)\n",
    "    bleus_2.append(bleu2)\n",
    "\n",
    "np.mean(bleus_2), np.mean(bleus_3), np.mean(bleus_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296a7a3",
   "metadata": {},
   "source": [
    "## ROUGE Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc652b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = ROUGEScore()\n",
    "r_f_measure_1, r_precision_1, r_recall_1 = [], [], []\n",
    "r_f_measure_2, r_precision_2, r_recall_2 = [], [], []\n",
    "r_f_measure_l, r_precision_l, r_recall_l = [], [], []\n",
    "for test_ref, test_pred in tqdm(zip(orig, preds)):\n",
    "    rouge_dict = rouge(test_pred, test_ref)\n",
    "    rouge1_fmeasure = rouge_dict[\"rouge1_fmeasure\"]\n",
    "    rouge1_precision = rouge_dict[\"rouge1_precision\"]\n",
    "    rouge1_recall = rouge_dict[\"rouge1_recall\"]\n",
    "    rouge2_fmeasure = rouge_dict[\"rouge2_fmeasure\"]\n",
    "    rouge2_precision = rouge_dict[\"rouge2_precision\"]\n",
    "    rouge2_recall = rouge_dict[\"rouge2_recall\"]\n",
    "    rougeL_fmeasure = rouge_dict[\"rougeL_fmeasure\"]\n",
    "    rougeL_precision = rouge_dict[\"rougeL_precision\"]\n",
    "    rougeL_recall = rouge_dict[\"rougeL_recall\"]\n",
    "    \n",
    "    r_f_measure_1.append(rouge1_fmeasure)\n",
    "    r_precision_1.append(rouge1_precision)\n",
    "    r_recall_1.append(rouge1_recall)\n",
    "    r_f_measure_2.append(rouge2_fmeasure)\n",
    "    r_precision_2.append(rouge2_precision)\n",
    "    r_recall_2.append(rouge2_recall)\n",
    "    r_f_measure_l.append(rougeL_fmeasure)\n",
    "    r_precision_l.append(rougeL_precision)\n",
    "    r_recall_l.append(rougeL_recall)\n",
    "    \n",
    "print(np.mean(r_f_measure_1), np.mean(r_precision_1), np.mean(r_recall_1))\n",
    "print(np.mean(r_f_measure_2), np.mean(r_precision_2), np.mean(r_recall_2))\n",
    "print(np.mean(r_f_measure_l), np.mean(r_precision_l), np.mean(r_recall_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0dd99",
   "metadata": {},
   "source": [
    "## BERT Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d87dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bertscore = BERTScore()\n",
    "scores = bertscore(orig, preds)\n",
    "np.mean(scores[\"precision\"]), np.mean(scores[\"recall\"]), np.mean(scores[\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46956bc1",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "pos_ratios, neu_ratios, neg_ratios = [], [], []\n",
    "for o, p in zip(orig, preds):\n",
    "    ss_orig = sid.polarity_scores(o)\n",
    "    ss_pred = sid.polarity_scores(p)\n",
    "    \n",
    "    ori_neg = ss_orig[\"neg\"]\n",
    "    ori_neu = ss_orig[\"neu\"]\n",
    "    ori_pos = ss_orig[\"pos\"]\n",
    "    \n",
    "    pred_neg = ss_pred[\"neg\"]\n",
    "    pred_neu = ss_pred[\"neu\"]\n",
    "    pred_pos = ss_pred[\"pos\"]\n",
    "    \n",
    "    if ori_neg > pred_neg:\n",
    "        neg_ratios.append(pred_neg/ori_neg)\n",
    "    elif ori_neg == 0 and pred_neg == 0:\n",
    "        neg_ratios.append(1)\n",
    "    else:\n",
    "        neg_ratios.append(ori_neg/pred_neg)\n",
    "        \n",
    "\n",
    "    if ori_neu > pred_neu:\n",
    "        neu_ratios.append(pred_neu/ori_neu)\n",
    "    elif ori_neu == 0 and pred_neu == 0:\n",
    "        neu_ratios.append(1)\n",
    "    else:\n",
    "        neu_ratios.append(ori_neu/pred_neu)\n",
    "\n",
    "    if ori_pos > pred_pos:\n",
    "        pos_ratios.append(pred_pos/ori_pos)\n",
    "    elif ori_pos == 0 and ori_pos == 0:\n",
    "        pos_ratios.append(1)\n",
    "    else:\n",
    "        pos_ratios.append(ori_pos/pred_pos)\n",
    "\n",
    "np.mean(pos_ratios), np.mean(neu_ratios), np.mean(neg_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647acd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
